{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "# CSE475 HW3, Problem 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "marked": true
    }
   },
   "source": [
    "## Introduction\n",
    "\n",
    "We will perform experiments with different classifiers using the breast cancer detection dataset given in \"data.txt\" on Canvas. It has 699 labeled data points with 11 entries for each point. The first 10 entries are ID, Clump Thickness, Uniformity of Cell Size, Uniformity of Cell Shape, Marginal Adhesion, Single Epithelial Cell Size, Bare Nuclei, Bland Chromatin, Normal Nucleoli, and Mitoses. The last entry represents the type of tumor (2 for benign, 4 for malignant). We will use 5-Fold Cross Validation (5-fold CV, review lecture 7) to find the best classifier among the following 6 classifiers for this dataset:\n",
    "\n",
    "1) Logistic Regression\n",
    "2) Naive Bayes Classifier\n",
    "3) Decision Tree\n",
    "4) K Nearest Neighbors\n",
    "5) Linear SVM\n",
    "6) SVM with RBF Kernel\n",
    "\n",
    "Note: 5-fold CV is used to find the best classifier, not the hyperpameters of each classifier (such as K for KNN). The best classifer selected by 5-fold CV is trained on the entire training data and tested on the test data. In 5-fold CV and the final training on the entire training data, please use the default hyperparamters provided by the scikit-learn library for each classifier, and use the built-in functions in the scikit-learn library to train and test each classifier. Please set the \"max_iter\" parameter of the LinearSVC function to a large number, such as 15000, to avoid warnings. By solving this problem, you will learn how to use the scikit-learn library to perform CV for classification tasks.\n",
    "\n",
    "Please follow the following steps:\n",
    "\n",
    "1) Download the dataset named \"data.txt\" on Canvas. You can get more details about the dataset from https://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(original) (UCI has a huge collection of datasets which can be used for various machine learning tasks)\n",
    "\n",
    "2) Separate the data into features and class labels. The features are all the entries between the second entry and the tenth entry inclusively, i.e. (Clump Thickness, Uniformity of Cell Size, Uniformity of Cell Shape, Marginal Adhesion, Single Epithelial Cell Size, Bare Nuclei, Bland Chromatin, Normal Nucleoli, and Mitoses). The last entry is the the class label. Please use the first 680 points as the training data, and the remaining 19 points as the test data.\n",
    "\n",
    "Steps 1)-2) have been done for your convenience.\n",
    "\n",
    "3) Use 5-fold CV on the training data to find the best classifier. Please use the KFold function in scikit-learn library for 5-fold CV. In each step of 5-fold CV, every classifier is trained on 4 folds (the training folds) and tested on the remaining fold (the test fold) with the corresponding classficiation accuracy (the percentage of data points classified correctly) on the test fold. Therefore, each classifier will be trained (and tested) for 5 times. Report the average classification accuracy of each classifier for 5-fold CV. Please shuffle the data for 5-fold CV which can be done by setting the \"shuffle\" parameter of the KFold function. Shuffling makes sure there is a mix of both classes in the training and test folds.\n",
    "\n",
    "4) Report the best classifier which has the maximum average classification accuracy in step 3), along with its average classification accuracy in step 3).\n",
    "\n",
    "6) Train the best classifier with the (scikit-learn) default hyperparameters on the entire training data, and report the classification accuracy of the best classifier on the test data. Again, if Linear SVM is the best classifer, please set the \"max_iter\" parameter of the LinearSVC function to a large number, such as 15000, to avoid warnings.\n",
    "\n",
    "There is no standard format for reporting the required results in the previous steps, and please choose your favorite way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-03-09T17:24:40.724060Z",
     "start_time": "2017-03-09T12:24:40.718739-05:00"
    },
    "run_control": {
     "marked": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "random_seed = 0\n",
    "np.random.seed(random_seed)\n",
    "\n",
    "# Read data\n",
    "data = np.genfromtxt(\"data.txt\", delimiter=\",\")\n",
    "\n",
    "\n",
    "# Separate features\n",
    "features = data[:, 1:-1].astype(np.float32)\n",
    "\n",
    "# Separate labels\n",
    "labels = data[:, -1]\n",
    "\n",
    "train_features = features[:680,:]\n",
    "train_labels = labels[:680]\n",
    "\n",
    "test_features = features[680:,:]\n",
    "test_labels = labels[680:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Linear SVM\": LinearSVC(max_iter=15000),\n",
    "    \"SVM with RBF Kernel\": SVC(kernel='rbf')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold Mean CV Accuracies: \n",
      "\n",
      "Logistic Regression = 0.9676\n",
      "Naive Bayes = 0.9618\n",
      "Decision Tree = 0.9353\n",
      "K-Nearest Neighbors = 0.9676\n",
      "Linear SVM = 0.9662\n",
      "SVM with RBF Kernel = 0.9721\n"
     ]
    }
   ],
   "source": [
    "kf = KFold(n_splits=5, shuffle=True, random_state=random_seed)\n",
    "cv_results = {}\n",
    "\n",
    "print(\"5-Fold Mean CV Accuracies: \\n\")\n",
    "\n",
    "for name, model in models.items():\n",
    "    scores = cross_val_score(model, train_features, train_labels, cv=kf, scoring='accuracy')\n",
    "    cv_results[name] = scores.mean()\n",
    "    print(f\"{name} = {scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best classifier based on CV: SVM with RBF Kernel with Mean CV Accuracy = 0.9721 \n",
      "\n",
      "Test Accuracy of SVM with RBF Kernel: 1.0000 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "best_clf_name = max(cv_results, key=cv_results.get)\n",
    "print(f\"\\nBest classifier based on CV: {best_clf_name} with Mean CV Accuracy = {cv_results[best_clf_name]:.4f} \\n\")\n",
    "\n",
    "best_model = models[best_clf_name]\n",
    "best_model.fit(train_features, train_labels)\n",
    "test_predictions = best_model.predict(test_features)\n",
    "test_accuracy = accuracy_score(test_labels, test_predictions)\n",
    "\n",
    "print(f\"Test Accuracy of {best_clf_name}: {test_accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "fml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "name": "Train_Test_Splits_Regularization_Exercises-ANSWERS",
  "notebookId": 2125319687183944
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
